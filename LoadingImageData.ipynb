{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/BertelsmannAITrack/blob/Lesson05/LoadingImageData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKnCPR0vH0Aq",
        "colab_type": "code",
        "outputId": "922f7d3c-a01b-405e-ba35-370103ea64c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Clone the repo.\n",
        "!git clone https://github.com/udacity/deep-learning-v2-pytorch.git\n",
        "\n",
        "# Change the working directory to the repo root.\n",
        "%cd ./deep-learning-v2-pytorch/intro-to-pytorch\n",
        "\n",
        "# Add the repo root to the Python path.\n",
        "import sys, os\n",
        "sys.path.append(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-learning-v2-pytorch'...\n",
            "remote: Enumerating objects: 1078, done.\u001b[K\n",
            "remote: Total 1078 (delta 0), reused 0 (delta 0), pack-reused 1078\u001b[K\n",
            "Receiving objects: 100% (1078/1078), 137.90 MiB | 28.49 MiB/s, done.\n",
            "Resolving deltas: 100% (484/484), done.\n",
            "/content/deep-learning-v2-pytorch/intro-to-pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBD-QpQeE-NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = \"retina\"\n",
        "\n",
        "import helper\n",
        "import fc_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7S2vW3aFEmK",
        "colab_type": "code",
        "outputId": "c210a9d2-a494-49e2-c792-db9527ff4993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST(\"~/.pytorch/F_MNIST_data/\", download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST(\"~/.pytorch/F_MNIST_data/\", download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 40960/26421880 [00:00<01:07, 391290.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:00, 80564448.55it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 517072.68it/s]\n",
            "  5%|â–         | 212992/4422102 [00:00<00:02, 1964791.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:00, 24824141.88it/s]                           \n",
            "8192it [00:00, 187449.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGaREHUdBdmF",
        "colab_type": "code",
        "outputId": "e0e53568-fc5e-460b-a3d2-f1806161ac3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "image, label = next(iter(trainloader))\n",
        "helper.imshow(image[0, :])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f33f3bd02e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAHPCAYAAAA1eFErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI+mLPQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 231,
              "height": 231
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WABVe4GzByxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the network, define the criterion and optimizer\n",
        "model = fc_model.Network(784, 10, [512, 256, 128])\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTJobqL2IHec",
        "colab_type": "code",
        "outputId": "f1c8a3ad-95b2-4a0a-8910-46bfc44e406b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2..  Training Loss: 1.703..  Test Loss: 0.982..  Test Accuracy: 0.608\n",
            "Epoch: 1/2..  Training Loss: 1.087..  Test Loss: 0.770..  Test Accuracy: 0.719\n",
            "Epoch: 1/2..  Training Loss: 0.926..  Test Loss: 0.690..  Test Accuracy: 0.739\n",
            "Epoch: 1/2..  Training Loss: 0.786..  Test Loss: 0.645..  Test Accuracy: 0.758\n",
            "Epoch: 1/2..  Training Loss: 0.778..  Test Loss: 0.630..  Test Accuracy: 0.749\n",
            "Epoch: 1/2..  Training Loss: 0.730..  Test Loss: 0.595..  Test Accuracy: 0.784\n",
            "Epoch: 1/2..  Training Loss: 0.684..  Test Loss: 0.572..  Test Accuracy: 0.782\n",
            "Epoch: 1/2..  Training Loss: 0.660..  Test Loss: 0.572..  Test Accuracy: 0.786\n",
            "Epoch: 1/2..  Training Loss: 0.682..  Test Loss: 0.566..  Test Accuracy: 0.793\n",
            "Epoch: 1/2..  Training Loss: 0.657..  Test Loss: 0.549..  Test Accuracy: 0.799\n",
            "Epoch: 1/2..  Training Loss: 0.631..  Test Loss: 0.532..  Test Accuracy: 0.802\n",
            "Epoch: 1/2..  Training Loss: 0.624..  Test Loss: 0.513..  Test Accuracy: 0.812\n",
            "Epoch: 1/2..  Training Loss: 0.637..  Test Loss: 0.528..  Test Accuracy: 0.803\n",
            "Epoch: 1/2..  Training Loss: 0.601..  Test Loss: 0.528..  Test Accuracy: 0.808\n",
            "Epoch: 1/2..  Training Loss: 0.616..  Test Loss: 0.507..  Test Accuracy: 0.818\n",
            "Epoch: 1/2..  Training Loss: 0.548..  Test Loss: 0.503..  Test Accuracy: 0.817\n",
            "Epoch: 1/2..  Training Loss: 0.546..  Test Loss: 0.503..  Test Accuracy: 0.809\n",
            "Epoch: 1/2..  Training Loss: 0.591..  Test Loss: 0.495..  Test Accuracy: 0.816\n",
            "Epoch: 1/2..  Training Loss: 0.558..  Test Loss: 0.484..  Test Accuracy: 0.825\n",
            "Epoch: 1/2..  Training Loss: 0.578..  Test Loss: 0.476..  Test Accuracy: 0.824\n",
            "Epoch: 1/2..  Training Loss: 0.575..  Test Loss: 0.478..  Test Accuracy: 0.823\n",
            "Epoch: 1/2..  Training Loss: 0.561..  Test Loss: 0.490..  Test Accuracy: 0.822\n",
            "Epoch: 1/2..  Training Loss: 0.571..  Test Loss: 0.466..  Test Accuracy: 0.828\n",
            "Epoch: 2/2..  Training Loss: 0.539..  Test Loss: 0.461..  Test Accuracy: 0.831\n",
            "Epoch: 2/2..  Training Loss: 0.535..  Test Loss: 0.470..  Test Accuracy: 0.826\n",
            "Epoch: 2/2..  Training Loss: 0.538..  Test Loss: 0.460..  Test Accuracy: 0.831\n",
            "Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.460..  Test Accuracy: 0.833\n",
            "Epoch: 2/2..  Training Loss: 0.522..  Test Loss: 0.472..  Test Accuracy: 0.827\n",
            "Epoch: 2/2..  Training Loss: 0.536..  Test Loss: 0.466..  Test Accuracy: 0.831\n",
            "Epoch: 2/2..  Training Loss: 0.557..  Test Loss: 0.467..  Test Accuracy: 0.828\n",
            "Epoch: 2/2..  Training Loss: 0.550..  Test Loss: 0.471..  Test Accuracy: 0.827\n",
            "Epoch: 2/2..  Training Loss: 0.529..  Test Loss: 0.458..  Test Accuracy: 0.831\n",
            "Epoch: 2/2..  Training Loss: 0.495..  Test Loss: 0.462..  Test Accuracy: 0.829\n",
            "Epoch: 2/2..  Training Loss: 0.544..  Test Loss: 0.456..  Test Accuracy: 0.833\n",
            "Epoch: 2/2..  Training Loss: 0.545..  Test Loss: 0.447..  Test Accuracy: 0.834\n",
            "Epoch: 2/2..  Training Loss: 0.508..  Test Loss: 0.464..  Test Accuracy: 0.827\n",
            "Epoch: 2/2..  Training Loss: 0.487..  Test Loss: 0.448..  Test Accuracy: 0.836\n",
            "Epoch: 2/2..  Training Loss: 0.558..  Test Loss: 0.437..  Test Accuracy: 0.844\n",
            "Epoch: 2/2..  Training Loss: 0.534..  Test Loss: 0.466..  Test Accuracy: 0.836\n",
            "Epoch: 2/2..  Training Loss: 0.559..  Test Loss: 0.446..  Test Accuracy: 0.836\n",
            "Epoch: 2/2..  Training Loss: 0.513..  Test Loss: 0.444..  Test Accuracy: 0.838\n",
            "Epoch: 2/2..  Training Loss: 0.491..  Test Loss: 0.442..  Test Accuracy: 0.840\n",
            "Epoch: 2/2..  Training Loss: 0.512..  Test Loss: 0.441..  Test Accuracy: 0.837\n",
            "Epoch: 2/2..  Training Loss: 0.499..  Test Loss: 0.445..  Test Accuracy: 0.838\n",
            "Epoch: 2/2..  Training Loss: 0.511..  Test Loss: 0.435..  Test Accuracy: 0.842\n",
            "Epoch: 2/2..  Training Loss: 0.537..  Test Loss: 0.430..  Test Accuracy: 0.842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlBJ6HK6Is2b",
        "colab_type": "code",
        "outputId": "633e9e38-fdc3-4d95-aa97-9747e701e377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# PyTorch networks are stored in a model's state_dict\n",
        "print(\"Our model: \\n\\n\", model, \"\\n\")\n",
        "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our model: \n",
            "\n",
            " Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ") \n",
            "\n",
            "The state dict keys: \n",
            "\n",
            " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nob4uBWKzfEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the state dict to a file \"checkpoint.pth\"\n",
        "torch.save(model.state_dict(), \"checkpoint.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH2ZMGzX0ILu",
        "colab_type": "code",
        "outputId": "24b9affb-f01c-43a5-a1ae-aa360fc451bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Load the state dict\n",
        "state_dict = torch.load(\"checkpoint.pth\")\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Egsni3o0gLa",
        "colab_type": "code",
        "outputId": "4919f1e2-2217-476b-e850-c54baa822f48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the state dict into the network\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LxYYUFR0ziS",
        "colab_type": "code",
        "outputId": "4ced4598-b467-4313-dc70-addaa3af5ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "# Model with different architecture will fail\n",
        "model = fc_model.Network(784, 10, [400, 200, 100])\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5530b1a255ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BibVRxSx20U-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Information about model architecture needs to be saved in the checkpoint, along with the state dict\n",
        "checkpoint = {\"input_size\": 784,\n",
        "              \"output_size\": 10,\n",
        "              \"hidden_layers\": [each.out_features for each in model.hidden_layers],\n",
        "              \"state_dict\": model.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, \"checkpoint.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qt77lVg32U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write a function to load checkpoints\n",
        "def load_checkpoint(filepath):\n",
        "  checkpoint = torch.load(filepath)\n",
        "  model = fc_model.Network(\n",
        "      checkpoint[\"input_size\"],\n",
        "      checkpoint[\"output_size\"],\n",
        "      checkpoint[\"hidden_layers\"])\n",
        "  model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVSf83DG4pEy",
        "colab_type": "code",
        "outputId": "0537941d-6ac7-44c2-dfdb-6712f557778e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# The checkpoint has all the necessary information to rebuild the trained model\n",
        "model = load_checkpoint(\"checkpoint.pth\")\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
            "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}