{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep $Q$-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use $Q$-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](fig/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://github.com/openai/gym). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Number of possible actions: 2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Number of possible actions\n",
    "print('Number of possible actions:', env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`.  You can see how many actions are possible from `env.action_space.n`, and to get a random action you can use `env.action_space.sample()`.  Passing in an action as an integer to `env.step` will generate the next step in the simulation.  This is general to all Gym games. \n",
    "\n",
    "In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to interact with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [] # actions that the agent selects\n",
    "rewards = [] # obtained rewards\n",
    "state = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()  # choose a random action\n",
    "    state, reward, done, _ = env.step(action) \n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the actions and rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: [0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n",
      "Rewards: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('Actions:', actions)\n",
    "print('Rewards:', rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each step while the game is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right.\n",
    "\n",
    "## $Q$-Network\n",
    "\n",
    "To keep track of the action values, we'll use a neural network that accepts a state $s$ as input.  The output will be $Q$-values for each available action $a$ (i.e., the output is **all** action values $Q(s,a)$ _corresponding to the input state $s$_).\n",
    "\n",
    "<img src=\"fig/q-network.png\" width=550px>\n",
    "\n",
    "For this Cart-Pole game, the state has four values: the position and velocity of the cart, and the position and velocity of the pole.  Thus, the neural network has **four inputs**, one for each value in the state, and **two outputs**, one for each possible action. \n",
    "\n",
    "As explored in the lesson, to get the training target, we'll first use the context provided by the state $s$ to choose an action $a$, then simulate the game using that action. This will get us the next state, $s'$, and the reward $r$. With that, we can calculate $\\hat{Q}(s,a) = r + \\gamma \\max_{a'}{Q(s', a')}$.  Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "Below is one implementation of the $Q$-network. It uses two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class QNetwork:\n",
    "    def __init__(self, learning_rate=0.01, state_size=4, \n",
    "                 action_size=2, hidden_size=10, \n",
    "                 name='QNetwork'):\n",
    "        # state inputs to the Q-network\n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "            \n",
    "            # One hot encode the actions to later choose the Q-value for the action\n",
    "            self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "            \n",
    "            # Target Q values for training\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "            \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)\n",
    "            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, hidden_size)\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.contrib.layers.fully_connected(self.fc2, action_size, \n",
    "                                                            activation_fn=None)\n",
    "            \n",
    "            ### Train with loss (targetQ - Q)^2\n",
    "            # output has length 2, for two actions. This next line chooses\n",
    "            # one value from output (per row) according to the one-hot encoded actions.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maximum capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Q$-Learning training algorithm\n",
    "\n",
    "We will use the below algorithm to train the network.  For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode $\\leftarrow 1$ **to** $M$ **do**\n",
    "  * Observe $s_0$\n",
    "  * **For** $t \\leftarrow 0$ **to** $T-1$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s_t,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**\n",
    "\n",
    "You are welcome (and encouraged!) to take the time to extend this code to implement some of the improvements that we discussed in the lesson, to include fixed $Q$ targets, double DQNs, prioritized replay, and/or dueling networks.\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcement learning is the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 200                # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 20                # experience mini-batch size\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here we re-initialize the simulation and pre-populate the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for ii in range(pretrain_length):\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: 11.0 Training loss: 1.0859 Explore P: 0.9989\n",
      "Episode: 2 Total reward: 17.0 Training loss: 1.1255 Explore P: 0.9972\n",
      "Episode: 3 Total reward: 14.0 Training loss: 1.0514 Explore P: 0.9959\n",
      "Episode: 4 Total reward: 11.0 Training loss: 1.0834 Explore P: 0.9948\n",
      "Episode: 5 Total reward: 21.0 Training loss: 1.1621 Explore P: 0.9927\n",
      "Episode: 6 Total reward: 15.0 Training loss: 1.1507 Explore P: 0.9912\n",
      "Episode: 7 Total reward: 30.0 Training loss: 1.0299 Explore P: 0.9883\n",
      "Episode: 8 Total reward: 24.0 Training loss: 1.0846 Explore P: 0.9859\n",
      "Episode: 9 Total reward: 10.0 Training loss: 1.2750 Explore P: 0.9850\n",
      "Episode: 10 Total reward: 18.0 Training loss: 1.2164 Explore P: 0.9832\n",
      "Episode: 11 Total reward: 24.0 Training loss: 1.0894 Explore P: 0.9809\n",
      "Episode: 12 Total reward: 16.0 Training loss: 1.2623 Explore P: 0.9793\n",
      "Episode: 13 Total reward: 31.0 Training loss: 1.3977 Explore P: 0.9763\n",
      "Episode: 14 Total reward: 21.0 Training loss: 1.2162 Explore P: 0.9743\n",
      "Episode: 15 Total reward: 9.0 Training loss: 1.3077 Explore P: 0.9734\n",
      "Episode: 16 Total reward: 16.0 Training loss: 1.4086 Explore P: 0.9719\n",
      "Episode: 17 Total reward: 18.0 Training loss: 1.2956 Explore P: 0.9702\n",
      "Episode: 18 Total reward: 24.0 Training loss: 1.1605 Explore P: 0.9679\n",
      "Episode: 19 Total reward: 17.0 Training loss: 1.4347 Explore P: 0.9662\n",
      "Episode: 20 Total reward: 17.0 Training loss: 1.5907 Explore P: 0.9646\n",
      "Episode: 21 Total reward: 23.0 Training loss: 1.8505 Explore P: 0.9624\n",
      "Episode: 22 Total reward: 31.0 Training loss: 2.1059 Explore P: 0.9595\n",
      "Episode: 23 Total reward: 12.0 Training loss: 2.0923 Explore P: 0.9583\n",
      "Episode: 24 Total reward: 20.0 Training loss: 2.0484 Explore P: 0.9564\n",
      "Episode: 25 Total reward: 18.0 Training loss: 2.0940 Explore P: 0.9547\n",
      "Episode: 26 Total reward: 32.0 Training loss: 2.2682 Explore P: 0.9517\n",
      "Episode: 27 Total reward: 26.0 Training loss: 2.2104 Explore P: 0.9493\n",
      "Episode: 28 Total reward: 14.0 Training loss: 3.8619 Explore P: 0.9480\n",
      "Episode: 29 Total reward: 27.0 Training loss: 4.1425 Explore P: 0.9454\n",
      "Episode: 30 Total reward: 41.0 Training loss: 2.9600 Explore P: 0.9416\n",
      "Episode: 31 Total reward: 36.0 Training loss: 3.3357 Explore P: 0.9383\n",
      "Episode: 32 Total reward: 33.0 Training loss: 2.8324 Explore P: 0.9352\n",
      "Episode: 33 Total reward: 35.0 Training loss: 11.8111 Explore P: 0.9320\n",
      "Episode: 34 Total reward: 15.0 Training loss: 5.9068 Explore P: 0.9306\n",
      "Episode: 35 Total reward: 26.0 Training loss: 3.2704 Explore P: 0.9282\n",
      "Episode: 36 Total reward: 55.0 Training loss: 7.4530 Explore P: 0.9232\n",
      "Episode: 37 Total reward: 72.0 Training loss: 11.7728 Explore P: 0.9166\n",
      "Episode: 38 Total reward: 13.0 Training loss: 15.2279 Explore P: 0.9154\n",
      "Episode: 39 Total reward: 11.0 Training loss: 6.7286 Explore P: 0.9144\n",
      "Episode: 40 Total reward: 15.0 Training loss: 7.6223 Explore P: 0.9131\n",
      "Episode: 41 Total reward: 11.0 Training loss: 27.3318 Explore P: 0.9121\n",
      "Episode: 42 Total reward: 14.0 Training loss: 10.7749 Explore P: 0.9108\n",
      "Episode: 43 Total reward: 24.0 Training loss: 29.8002 Explore P: 0.9087\n",
      "Episode: 44 Total reward: 28.0 Training loss: 5.2369 Explore P: 0.9061\n",
      "Episode: 45 Total reward: 20.0 Training loss: 12.2579 Explore P: 0.9044\n",
      "Episode: 46 Total reward: 48.0 Training loss: 5.7467 Explore P: 0.9001\n",
      "Episode: 47 Total reward: 11.0 Training loss: 24.1586 Explore P: 0.8991\n",
      "Episode: 48 Total reward: 12.0 Training loss: 12.9466 Explore P: 0.8980\n",
      "Episode: 49 Total reward: 16.0 Training loss: 45.6628 Explore P: 0.8966\n",
      "Episode: 50 Total reward: 38.0 Training loss: 28.0381 Explore P: 0.8932\n",
      "Episode: 51 Total reward: 18.0 Training loss: 21.5815 Explore P: 0.8917\n",
      "Episode: 52 Total reward: 30.0 Training loss: 6.8529 Explore P: 0.8890\n",
      "Episode: 53 Total reward: 18.0 Training loss: 5.5698 Explore P: 0.8874\n",
      "Episode: 54 Total reward: 31.0 Training loss: 23.4811 Explore P: 0.8847\n",
      "Episode: 55 Total reward: 8.0 Training loss: 7.5110 Explore P: 0.8840\n",
      "Episode: 56 Total reward: 13.0 Training loss: 27.8979 Explore P: 0.8829\n",
      "Episode: 57 Total reward: 11.0 Training loss: 6.8420 Explore P: 0.8819\n",
      "Episode: 58 Total reward: 15.0 Training loss: 28.2650 Explore P: 0.8806\n",
      "Episode: 59 Total reward: 10.0 Training loss: 37.5830 Explore P: 0.8797\n",
      "Episode: 60 Total reward: 18.0 Training loss: 23.0988 Explore P: 0.8782\n",
      "Episode: 61 Total reward: 25.0 Training loss: 23.2399 Explore P: 0.8760\n",
      "Episode: 62 Total reward: 9.0 Training loss: 7.4121 Explore P: 0.8752\n",
      "Episode: 63 Total reward: 17.0 Training loss: 41.7720 Explore P: 0.8738\n",
      "Episode: 64 Total reward: 15.0 Training loss: 5.4924 Explore P: 0.8725\n",
      "Episode: 65 Total reward: 10.0 Training loss: 36.6296 Explore P: 0.8716\n",
      "Episode: 66 Total reward: 23.0 Training loss: 6.6691 Explore P: 0.8696\n",
      "Episode: 67 Total reward: 14.0 Training loss: 57.8351 Explore P: 0.8684\n",
      "Episode: 68 Total reward: 15.0 Training loss: 8.3254 Explore P: 0.8671\n",
      "Episode: 69 Total reward: 24.0 Training loss: 6.5703 Explore P: 0.8651\n",
      "Episode: 70 Total reward: 15.0 Training loss: 5.0624 Explore P: 0.8638\n",
      "Episode: 71 Total reward: 11.0 Training loss: 46.9320 Explore P: 0.8629\n",
      "Episode: 72 Total reward: 19.0 Training loss: 57.0911 Explore P: 0.8612\n",
      "Episode: 73 Total reward: 12.0 Training loss: 64.8981 Explore P: 0.8602\n",
      "Episode: 74 Total reward: 10.0 Training loss: 6.1621 Explore P: 0.8594\n",
      "Episode: 75 Total reward: 23.0 Training loss: 64.1328 Explore P: 0.8574\n",
      "Episode: 76 Total reward: 13.0 Training loss: 102.4278 Explore P: 0.8563\n",
      "Episode: 77 Total reward: 16.0 Training loss: 57.2226 Explore P: 0.8550\n",
      "Episode: 78 Total reward: 13.0 Training loss: 88.9193 Explore P: 0.8539\n",
      "Episode: 79 Total reward: 11.0 Training loss: 27.1486 Explore P: 0.8529\n",
      "Episode: 80 Total reward: 21.0 Training loss: 49.0053 Explore P: 0.8512\n",
      "Episode: 81 Total reward: 11.0 Training loss: 99.5048 Explore P: 0.8503\n",
      "Episode: 82 Total reward: 39.0 Training loss: 72.5719 Explore P: 0.8470\n",
      "Episode: 83 Total reward: 12.0 Training loss: 5.4428 Explore P: 0.8460\n",
      "Episode: 84 Total reward: 28.0 Training loss: 37.3023 Explore P: 0.8436\n",
      "Episode: 85 Total reward: 31.0 Training loss: 6.1989 Explore P: 0.8411\n",
      "Episode: 86 Total reward: 20.0 Training loss: 61.5415 Explore P: 0.8394\n",
      "Episode: 87 Total reward: 8.0 Training loss: 9.1894 Explore P: 0.8387\n",
      "Episode: 88 Total reward: 16.0 Training loss: 37.2016 Explore P: 0.8374\n",
      "Episode: 89 Total reward: 9.0 Training loss: 113.2133 Explore P: 0.8367\n",
      "Episode: 90 Total reward: 14.0 Training loss: 6.6964 Explore P: 0.8355\n",
      "Episode: 91 Total reward: 31.0 Training loss: 43.7489 Explore P: 0.8330\n",
      "Episode: 92 Total reward: 32.0 Training loss: 3.6143 Explore P: 0.8303\n",
      "Episode: 93 Total reward: 14.0 Training loss: 3.6760 Explore P: 0.8292\n",
      "Episode: 94 Total reward: 11.0 Training loss: 54.1603 Explore P: 0.8283\n",
      "Episode: 95 Total reward: 16.0 Training loss: 123.0304 Explore P: 0.8270\n",
      "Episode: 96 Total reward: 11.0 Training loss: 67.8422 Explore P: 0.8261\n",
      "Episode: 97 Total reward: 9.0 Training loss: 32.6625 Explore P: 0.8253\n",
      "Episode: 98 Total reward: 14.0 Training loss: 85.4174 Explore P: 0.8242\n",
      "Episode: 99 Total reward: 28.0 Training loss: 36.0787 Explore P: 0.8219\n",
      "Episode: 100 Total reward: 26.0 Training loss: 2.5221 Explore P: 0.8198\n",
      "Episode: 101 Total reward: 16.0 Training loss: 2.5658 Explore P: 0.8185\n",
      "Episode: 102 Total reward: 17.0 Training loss: 53.3561 Explore P: 0.8171\n",
      "Episode: 103 Total reward: 26.0 Training loss: 42.6359 Explore P: 0.8151\n",
      "Episode: 104 Total reward: 24.0 Training loss: 55.9544 Explore P: 0.8131\n",
      "Episode: 105 Total reward: 33.0 Training loss: 39.7170 Explore P: 0.8105\n",
      "Episode: 106 Total reward: 23.0 Training loss: 3.7542 Explore P: 0.8086\n",
      "Episode: 107 Total reward: 17.0 Training loss: 3.2973 Explore P: 0.8073\n",
      "Episode: 108 Total reward: 18.0 Training loss: 2.7758 Explore P: 0.8058\n",
      "Episode: 109 Total reward: 13.0 Training loss: 113.0468 Explore P: 0.8048\n",
      "Episode: 110 Total reward: 28.0 Training loss: 44.1089 Explore P: 0.8026\n",
      "Episode: 111 Total reward: 17.0 Training loss: 76.6624 Explore P: 0.8012\n",
      "Episode: 112 Total reward: 36.0 Training loss: 153.6499 Explore P: 0.7984\n",
      "Episode: 113 Total reward: 29.0 Training loss: 2.7572 Explore P: 0.7961\n",
      "Episode: 114 Total reward: 34.0 Training loss: 2.4550 Explore P: 0.7934\n",
      "Episode: 115 Total reward: 18.0 Training loss: 2.3667 Explore P: 0.7920\n",
      "Episode: 116 Total reward: 29.0 Training loss: 42.2042 Explore P: 0.7898\n",
      "Episode: 117 Total reward: 13.0 Training loss: 39.3980 Explore P: 0.7888\n",
      "Episode: 118 Total reward: 16.0 Training loss: 75.6814 Explore P: 0.7875\n",
      "Episode: 119 Total reward: 8.0 Training loss: 30.5470 Explore P: 0.7869\n",
      "Episode: 120 Total reward: 11.0 Training loss: 1.7723 Explore P: 0.7860\n",
      "Episode: 121 Total reward: 17.0 Training loss: 34.3874 Explore P: 0.7847\n",
      "Episode: 122 Total reward: 8.0 Training loss: 28.1844 Explore P: 0.7841\n",
      "Episode: 123 Total reward: 10.0 Training loss: 42.7334 Explore P: 0.7833\n",
      "Episode: 124 Total reward: 13.0 Training loss: 1.9257 Explore P: 0.7823\n",
      "Episode: 125 Total reward: 13.0 Training loss: 72.1561 Explore P: 0.7813\n",
      "Episode: 126 Total reward: 14.0 Training loss: 26.8207 Explore P: 0.7802\n",
      "Episode: 127 Total reward: 18.0 Training loss: 69.9725 Explore P: 0.7789\n",
      "Episode: 128 Total reward: 11.0 Training loss: 68.0561 Explore P: 0.7780\n",
      "Episode: 129 Total reward: 27.0 Training loss: 38.0045 Explore P: 0.7759\n",
      "Episode: 130 Total reward: 20.0 Training loss: 36.8727 Explore P: 0.7744\n",
      "Episode: 131 Total reward: 23.0 Training loss: 27.7849 Explore P: 0.7727\n",
      "Episode: 132 Total reward: 17.0 Training loss: 39.0908 Explore P: 0.7714\n",
      "Episode: 133 Total reward: 10.0 Training loss: 38.6128 Explore P: 0.7706\n",
      "Episode: 134 Total reward: 11.0 Training loss: 46.8202 Explore P: 0.7698\n",
      "Episode: 135 Total reward: 11.0 Training loss: 42.6630 Explore P: 0.7689\n",
      "Episode: 136 Total reward: 9.0 Training loss: 73.1260 Explore P: 0.7682\n",
      "Episode: 137 Total reward: 14.0 Training loss: 1.0111 Explore P: 0.7672\n",
      "Episode: 138 Total reward: 23.0 Training loss: 42.3529 Explore P: 0.7654\n",
      "Episode: 139 Total reward: 14.0 Training loss: 29.0170 Explore P: 0.7644\n",
      "Episode: 140 Total reward: 17.0 Training loss: 1.2681 Explore P: 0.7631\n",
      "Episode: 141 Total reward: 67.0 Training loss: 1.1036 Explore P: 0.7581\n",
      "Episode: 142 Total reward: 12.0 Training loss: 26.0765 Explore P: 0.7572\n",
      "Episode: 143 Total reward: 26.0 Training loss: 45.7708 Explore P: 0.7552\n",
      "Episode: 144 Total reward: 29.0 Training loss: 1.1397 Explore P: 0.7531\n",
      "Episode: 145 Total reward: 13.0 Training loss: 62.9159 Explore P: 0.7521\n",
      "Episode: 146 Total reward: 12.0 Training loss: 1.0791 Explore P: 0.7512\n",
      "Episode: 147 Total reward: 16.0 Training loss: 1.0756 Explore P: 0.7500\n",
      "Episode: 148 Total reward: 19.0 Training loss: 0.6140 Explore P: 0.7486\n",
      "Episode: 149 Total reward: 22.0 Training loss: 41.9533 Explore P: 0.7470\n",
      "Episode: 150 Total reward: 12.0 Training loss: 0.8960 Explore P: 0.7461\n",
      "Episode: 151 Total reward: 28.0 Training loss: 103.7582 Explore P: 0.7441\n",
      "Episode: 152 Total reward: 25.0 Training loss: 37.2037 Explore P: 0.7422\n",
      "Episode: 153 Total reward: 24.0 Training loss: 1.5180 Explore P: 0.7405\n",
      "Episode: 154 Total reward: 25.0 Training loss: 17.2699 Explore P: 0.7387\n",
      "Episode: 155 Total reward: 9.0 Training loss: 19.0311 Explore P: 0.7380\n",
      "Episode: 156 Total reward: 15.0 Training loss: 17.4316 Explore P: 0.7369\n",
      "Episode: 157 Total reward: 10.0 Training loss: 1.7509 Explore P: 0.7362\n",
      "Episode: 158 Total reward: 11.0 Training loss: 74.2560 Explore P: 0.7354\n",
      "Episode: 159 Total reward: 22.0 Training loss: 1.3378 Explore P: 0.7338\n",
      "Episode: 160 Total reward: 13.0 Training loss: 51.3557 Explore P: 0.7329\n",
      "Episode: 161 Total reward: 10.0 Training loss: 1.1534 Explore P: 0.7321\n",
      "Episode: 162 Total reward: 9.0 Training loss: 130.3659 Explore P: 0.7315\n",
      "Episode: 163 Total reward: 20.0 Training loss: 17.3647 Explore P: 0.7300\n",
      "Episode: 164 Total reward: 10.0 Training loss: 19.3273 Explore P: 0.7293\n",
      "Episode: 165 Total reward: 10.0 Training loss: 1.2845 Explore P: 0.7286\n",
      "Episode: 166 Total reward: 19.0 Training loss: 0.9936 Explore P: 0.7272\n",
      "Episode: 167 Total reward: 13.0 Training loss: 1.0567 Explore P: 0.7263\n",
      "Episode: 168 Total reward: 23.0 Training loss: 71.9191 Explore P: 0.7247\n",
      "Episode: 169 Total reward: 15.0 Training loss: 31.6568 Explore P: 0.7236\n",
      "Episode: 170 Total reward: 13.0 Training loss: 34.4879 Explore P: 0.7227\n",
      "Episode: 171 Total reward: 19.0 Training loss: 1.4326 Explore P: 0.7213\n",
      "Episode: 172 Total reward: 11.0 Training loss: 65.3231 Explore P: 0.7205\n",
      "Episode: 173 Total reward: 37.0 Training loss: 28.9554 Explore P: 0.7179\n",
      "Episode: 174 Total reward: 13.0 Training loss: 88.9683 Explore P: 0.7170\n",
      "Episode: 175 Total reward: 12.0 Training loss: 40.9738 Explore P: 0.7161\n",
      "Episode: 176 Total reward: 11.0 Training loss: 1.6167 Explore P: 0.7154\n",
      "Episode: 177 Total reward: 13.0 Training loss: 55.1480 Explore P: 0.7144\n",
      "Episode: 178 Total reward: 13.0 Training loss: 39.0661 Explore P: 0.7135\n",
      "Episode: 179 Total reward: 11.0 Training loss: 40.9375 Explore P: 0.7128\n",
      "Episode: 180 Total reward: 23.0 Training loss: 36.8270 Explore P: 0.7111\n",
      "Episode: 181 Total reward: 23.0 Training loss: 53.9284 Explore P: 0.7095\n",
      "Episode: 182 Total reward: 11.0 Training loss: 15.1291 Explore P: 0.7088\n",
      "Episode: 183 Total reward: 23.0 Training loss: 43.7597 Explore P: 0.7072\n",
      "Episode: 184 Total reward: 17.0 Training loss: 80.0282 Explore P: 0.7060\n",
      "Episode: 185 Total reward: 11.0 Training loss: 37.3155 Explore P: 0.7052\n",
      "Episode: 186 Total reward: 18.0 Training loss: 13.8511 Explore P: 0.7040\n",
      "Episode: 187 Total reward: 22.0 Training loss: 44.4251 Explore P: 0.7024\n",
      "Episode: 188 Total reward: 9.0 Training loss: 0.8837 Explore P: 0.7018\n",
      "Episode: 189 Total reward: 12.0 Training loss: 1.1200 Explore P: 0.7010\n",
      "Episode: 190 Total reward: 27.0 Training loss: 12.2508 Explore P: 0.6991\n",
      "Episode: 191 Total reward: 13.0 Training loss: 47.4048 Explore P: 0.6982\n",
      "Episode: 192 Total reward: 12.0 Training loss: 78.8967 Explore P: 0.6974\n",
      "Episode: 193 Total reward: 11.0 Training loss: 1.6059 Explore P: 0.6966\n",
      "Episode: 194 Total reward: 28.0 Training loss: 1.6662 Explore P: 0.6947\n",
      "Episode: 195 Total reward: 8.0 Training loss: 1.8305 Explore P: 0.6942\n",
      "Episode: 196 Total reward: 15.0 Training loss: 1.8219 Explore P: 0.6931\n",
      "Episode: 197 Total reward: 18.0 Training loss: 13.2134 Explore P: 0.6919\n",
      "Episode: 198 Total reward: 17.0 Training loss: 47.7495 Explore P: 0.6908\n",
      "Episode: 199 Total reward: 10.0 Training loss: 73.7608 Explore P: 0.6901\n",
      "Episode: 200 Total reward: 7.0 Training loss: 1.7248 Explore P: 0.6896\n",
      "Episode: 201 Total reward: 9.0 Training loss: 1.3602 Explore P: 0.6890\n",
      "Episode: 202 Total reward: 13.0 Training loss: 1.2834 Explore P: 0.6881\n",
      "Episode: 203 Total reward: 15.0 Training loss: 1.1729 Explore P: 0.6871\n",
      "Episode: 204 Total reward: 25.0 Training loss: 13.0469 Explore P: 0.6854\n",
      "Episode: 205 Total reward: 27.0 Training loss: 59.6871 Explore P: 0.6836\n",
      "Episode: 206 Total reward: 17.0 Training loss: 1.3554 Explore P: 0.6824\n",
      "Episode: 207 Total reward: 15.0 Training loss: 32.2357 Explore P: 0.6814\n",
      "Episode: 208 Total reward: 24.0 Training loss: 103.7482 Explore P: 0.6798\n",
      "Episode: 209 Total reward: 9.0 Training loss: 35.2377 Explore P: 0.6792\n",
      "Episode: 210 Total reward: 12.0 Training loss: 1.4049 Explore P: 0.6784\n",
      "Episode: 211 Total reward: 23.0 Training loss: 1.3635 Explore P: 0.6769\n",
      "Episode: 212 Total reward: 9.0 Training loss: 47.6781 Explore P: 0.6763\n",
      "Episode: 213 Total reward: 29.0 Training loss: 1.2390 Explore P: 0.6743\n",
      "Episode: 214 Total reward: 13.0 Training loss: 45.7825 Explore P: 0.6735\n",
      "Episode: 215 Total reward: 10.0 Training loss: 1.3585 Explore P: 0.6728\n",
      "Episode: 216 Total reward: 13.0 Training loss: 0.9756 Explore P: 0.6720\n",
      "Episode: 217 Total reward: 12.0 Training loss: 1.0286 Explore P: 0.6712\n",
      "Episode: 218 Total reward: 20.0 Training loss: 45.2840 Explore P: 0.6698\n",
      "Episode: 219 Total reward: 10.0 Training loss: 1.1524 Explore P: 0.6692\n",
      "Episode: 220 Total reward: 19.0 Training loss: 62.9631 Explore P: 0.6679\n",
      "Episode: 221 Total reward: 16.0 Training loss: 15.2888 Explore P: 0.6669\n",
      "Episode: 222 Total reward: 14.0 Training loss: 41.8601 Explore P: 0.6660\n",
      "Episode: 223 Total reward: 16.0 Training loss: 1.2757 Explore P: 0.6649\n",
      "Episode: 224 Total reward: 12.0 Training loss: 14.6063 Explore P: 0.6641\n",
      "Episode: 225 Total reward: 25.0 Training loss: 0.7965 Explore P: 0.6625\n",
      "Episode: 226 Total reward: 12.0 Training loss: 77.1840 Explore P: 0.6617\n",
      "Episode: 227 Total reward: 41.0 Training loss: 1.4173 Explore P: 0.6590\n",
      "Episode: 228 Total reward: 18.0 Training loss: 1.2605 Explore P: 0.6579\n",
      "Episode: 229 Total reward: 13.0 Training loss: 1.2158 Explore P: 0.6570\n",
      "Episode: 230 Total reward: 13.0 Training loss: 28.2348 Explore P: 0.6562\n",
      "Episode: 231 Total reward: 17.0 Training loss: 12.4226 Explore P: 0.6551\n",
      "Episode: 232 Total reward: 13.0 Training loss: 53.0743 Explore P: 0.6543\n",
      "Episode: 233 Total reward: 14.0 Training loss: 28.8909 Explore P: 0.6534\n",
      "Episode: 234 Total reward: 15.0 Training loss: 0.6328 Explore P: 0.6524\n",
      "Episode: 235 Total reward: 33.0 Training loss: 1.0846 Explore P: 0.6503\n",
      "Episode: 236 Total reward: 30.0 Training loss: 0.7171 Explore P: 0.6484\n",
      "Episode: 237 Total reward: 37.0 Training loss: 26.1168 Explore P: 0.6460\n",
      "Episode: 238 Total reward: 31.0 Training loss: 25.0034 Explore P: 0.6440\n",
      "Episode: 239 Total reward: 22.0 Training loss: 34.4628 Explore P: 0.6426\n",
      "Episode: 240 Total reward: 14.0 Training loss: 26.8284 Explore P: 0.6418\n",
      "Episode: 241 Total reward: 31.0 Training loss: 24.3397 Explore P: 0.6398\n",
      "Episode: 242 Total reward: 21.0 Training loss: 1.1015 Explore P: 0.6385\n",
      "Episode: 243 Total reward: 21.0 Training loss: 21.3047 Explore P: 0.6372\n",
      "Episode: 244 Total reward: 26.0 Training loss: 1.0283 Explore P: 0.6355\n",
      "Episode: 245 Total reward: 24.0 Training loss: 45.9061 Explore P: 0.6340\n",
      "Episode: 246 Total reward: 27.0 Training loss: 22.8418 Explore P: 0.6324\n",
      "Episode: 247 Total reward: 17.0 Training loss: 1.1345 Explore P: 0.6313\n",
      "Episode: 248 Total reward: 11.0 Training loss: 22.3100 Explore P: 0.6306\n",
      "Episode: 249 Total reward: 28.0 Training loss: 1.0141 Explore P: 0.6289\n",
      "Episode: 250 Total reward: 22.0 Training loss: 33.9648 Explore P: 0.6275\n",
      "Episode: 251 Total reward: 30.0 Training loss: 74.0248 Explore P: 0.6257\n",
      "Episode: 252 Total reward: 49.0 Training loss: 0.8485 Explore P: 0.6227\n",
      "Episode: 253 Total reward: 50.0 Training loss: 23.3409 Explore P: 0.6196\n",
      "Episode: 254 Total reward: 17.0 Training loss: 37.7903 Explore P: 0.6186\n",
      "Episode: 255 Total reward: 14.0 Training loss: 11.6897 Explore P: 0.6177\n",
      "Episode: 256 Total reward: 15.0 Training loss: 18.6738 Explore P: 0.6168\n",
      "Episode: 257 Total reward: 45.0 Training loss: 44.2459 Explore P: 0.6141\n",
      "Episode: 258 Total reward: 11.0 Training loss: 17.8232 Explore P: 0.6134\n",
      "Episode: 259 Total reward: 57.0 Training loss: 0.7703 Explore P: 0.6100\n",
      "Episode: 260 Total reward: 55.0 Training loss: 54.5119 Explore P: 0.6067\n",
      "Episode: 261 Total reward: 35.0 Training loss: 0.9662 Explore P: 0.6046\n",
      "Episode: 262 Total reward: 39.0 Training loss: 1.0054 Explore P: 0.6023\n",
      "Episode: 263 Total reward: 63.0 Training loss: 16.2004 Explore P: 0.5986\n",
      "Episode: 264 Total reward: 9.0 Training loss: 10.0214 Explore P: 0.5980\n",
      "Episode: 265 Total reward: 30.0 Training loss: 15.8978 Explore P: 0.5963\n",
      "Episode: 266 Total reward: 53.0 Training loss: 17.1612 Explore P: 0.5932\n",
      "Episode: 267 Total reward: 49.0 Training loss: 27.0683 Explore P: 0.5903\n",
      "Episode: 268 Total reward: 18.0 Training loss: 19.7011 Explore P: 0.5893\n",
      "Episode: 269 Total reward: 21.0 Training loss: 10.2352 Explore P: 0.5881\n",
      "Episode: 270 Total reward: 39.0 Training loss: 1.1525 Explore P: 0.5858\n",
      "Episode: 271 Total reward: 14.0 Training loss: 7.3587 Explore P: 0.5850\n",
      "Episode: 272 Total reward: 17.0 Training loss: 0.7593 Explore P: 0.5840\n",
      "Episode: 273 Total reward: 26.0 Training loss: 20.1035 Explore P: 0.5826\n",
      "Episode: 274 Total reward: 25.0 Training loss: 26.0623 Explore P: 0.5811\n",
      "Episode: 275 Total reward: 46.0 Training loss: 1.2684 Explore P: 0.5785\n",
      "Episode: 276 Total reward: 11.0 Training loss: 18.4063 Explore P: 0.5779\n",
      "Episode: 277 Total reward: 67.0 Training loss: 16.3233 Explore P: 0.5741\n",
      "Episode: 278 Total reward: 79.0 Training loss: 13.7215 Explore P: 0.5696\n",
      "Episode: 279 Total reward: 56.0 Training loss: 43.9705 Explore P: 0.5665\n",
      "Episode: 280 Total reward: 45.0 Training loss: 1.5057 Explore P: 0.5640\n",
      "Episode: 281 Total reward: 40.0 Training loss: 1.0796 Explore P: 0.5618\n",
      "Episode: 282 Total reward: 81.0 Training loss: 18.1564 Explore P: 0.5574\n",
      "Episode: 283 Total reward: 58.0 Training loss: 16.3996 Explore P: 0.5542\n",
      "Episode: 284 Total reward: 92.0 Training loss: 16.9941 Explore P: 0.5492\n",
      "Episode: 285 Total reward: 48.0 Training loss: 25.2328 Explore P: 0.5466\n",
      "Episode: 286 Total reward: 32.0 Training loss: 15.1205 Explore P: 0.5449\n",
      "Episode: 287 Total reward: 77.0 Training loss: 1.2608 Explore P: 0.5408\n",
      "Episode: 288 Total reward: 44.0 Training loss: 1.3949 Explore P: 0.5385\n",
      "Episode: 289 Total reward: 11.0 Training loss: 18.1041 Explore P: 0.5379\n",
      "Episode: 290 Total reward: 44.0 Training loss: 15.1720 Explore P: 0.5356\n",
      "Episode: 291 Total reward: 39.0 Training loss: 1.1789 Explore P: 0.5335\n",
      "Episode: 292 Total reward: 48.0 Training loss: 16.5762 Explore P: 0.5310\n",
      "Episode: 293 Total reward: 60.0 Training loss: 17.8536 Explore P: 0.5279\n",
      "Episode: 294 Total reward: 76.0 Training loss: 1.2960 Explore P: 0.5240\n",
      "Episode: 295 Total reward: 46.0 Training loss: 20.1808 Explore P: 0.5216\n",
      "Episode: 296 Total reward: 132.0 Training loss: 0.9088 Explore P: 0.5149\n",
      "Episode: 297 Total reward: 134.0 Training loss: 55.5341 Explore P: 0.5082\n",
      "Episode: 298 Total reward: 42.0 Training loss: 25.9575 Explore P: 0.5061\n",
      "Episode: 299 Total reward: 44.0 Training loss: 1.0862 Explore P: 0.5039\n",
      "Episode: 300 Total reward: 12.0 Training loss: 21.1538 Explore P: 0.5033\n",
      "Episode: 301 Total reward: 29.0 Training loss: 1.0339 Explore P: 0.5019\n",
      "Episode: 302 Total reward: 39.0 Training loss: 1.5703 Explore P: 0.5000\n",
      "Episode: 303 Total reward: 92.0 Training loss: 1.7961 Explore P: 0.4955\n",
      "Episode: 304 Total reward: 27.0 Training loss: 0.7420 Explore P: 0.4942\n",
      "Episode: 305 Total reward: 42.0 Training loss: 32.1578 Explore P: 0.4922\n",
      "Episode: 306 Total reward: 31.0 Training loss: 47.9364 Explore P: 0.4907\n",
      "Episode: 307 Total reward: 32.0 Training loss: 24.4501 Explore P: 0.4891\n",
      "Episode: 308 Total reward: 139.0 Training loss: 26.2468 Explore P: 0.4825\n",
      "Episode: 309 Total reward: 51.0 Training loss: 1.2789 Explore P: 0.4801\n",
      "Episode: 310 Total reward: 47.0 Training loss: 32.5648 Explore P: 0.4779\n",
      "Episode: 311 Total reward: 36.0 Training loss: 1.8484 Explore P: 0.4762\n",
      "Episode: 312 Total reward: 37.0 Training loss: 88.0937 Explore P: 0.4745\n",
      "Episode: 313 Total reward: 58.0 Training loss: 25.7508 Explore P: 0.4718\n",
      "Episode: 314 Total reward: 100.0 Training loss: 1.3742 Explore P: 0.4672\n",
      "Episode: 315 Total reward: 27.0 Training loss: 1.4029 Explore P: 0.4660\n",
      "Episode: 316 Total reward: 54.0 Training loss: 24.1209 Explore P: 0.4635\n",
      "Episode: 317 Total reward: 31.0 Training loss: 43.1170 Explore P: 0.4621\n",
      "Episode: 318 Total reward: 20.0 Training loss: 35.3177 Explore P: 0.4612\n",
      "Episode: 319 Total reward: 45.0 Training loss: 1.7788 Explore P: 0.4592\n",
      "Episode: 320 Total reward: 32.0 Training loss: 1.6698 Explore P: 0.4578\n",
      "Episode: 321 Total reward: 36.0 Training loss: 56.3737 Explore P: 0.4562\n",
      "Episode: 322 Total reward: 64.0 Training loss: 43.7505 Explore P: 0.4533\n",
      "Episode: 323 Total reward: 15.0 Training loss: 42.9029 Explore P: 0.4527\n",
      "Episode: 324 Total reward: 34.0 Training loss: 22.0347 Explore P: 0.4512\n",
      "Episode: 325 Total reward: 41.0 Training loss: 1.3389 Explore P: 0.4494\n",
      "Episode: 326 Total reward: 29.0 Training loss: 64.8296 Explore P: 0.4481\n",
      "Episode: 327 Total reward: 77.0 Training loss: 2.8772 Explore P: 0.4447\n",
      "Episode: 328 Total reward: 40.0 Training loss: 1.8005 Explore P: 0.4430\n",
      "Episode: 329 Total reward: 82.0 Training loss: 1.7561 Explore P: 0.4394\n",
      "Episode: 330 Total reward: 117.0 Training loss: 42.5026 Explore P: 0.4345\n",
      "Episode: 331 Total reward: 139.0 Training loss: 26.1615 Explore P: 0.4286\n",
      "Episode: 332 Total reward: 58.0 Training loss: 38.0878 Explore P: 0.4262\n",
      "Episode: 333 Total reward: 35.0 Training loss: 32.0497 Explore P: 0.4247\n",
      "Episode: 334 Total reward: 107.0 Training loss: 2.0636 Explore P: 0.4203\n",
      "Episode: 335 Total reward: 28.0 Training loss: 98.6618 Explore P: 0.4192\n",
      "Episode: 336 Total reward: 66.0 Training loss: 26.8237 Explore P: 0.4165\n",
      "Episode: 337 Total reward: 36.0 Training loss: 76.5972 Explore P: 0.4150\n",
      "Episode: 338 Total reward: 142.0 Training loss: 50.1153 Explore P: 0.4093\n",
      "Episode: 339 Total reward: 85.0 Training loss: 75.4434 Explore P: 0.4059\n",
      "Episode: 340 Total reward: 25.0 Training loss: 2.1908 Explore P: 0.4049\n",
      "Episode: 341 Total reward: 29.0 Training loss: 20.3396 Explore P: 0.4038\n",
      "Episode: 342 Total reward: 80.0 Training loss: 1.3272 Explore P: 0.4006\n",
      "Episode: 343 Total reward: 55.0 Training loss: 36.0140 Explore P: 0.3985\n",
      "Episode: 344 Total reward: 79.0 Training loss: 74.0023 Explore P: 0.3954\n",
      "Episode: 345 Total reward: 89.0 Training loss: 2.1250 Explore P: 0.3920\n",
      "Episode: 346 Total reward: 58.0 Training loss: 3.1552 Explore P: 0.3898\n",
      "Episode: 347 Total reward: 100.0 Training loss: 67.5757 Explore P: 0.3860\n",
      "Episode: 348 Total reward: 48.0 Training loss: 29.3757 Explore P: 0.3842\n",
      "Episode: 349 Total reward: 57.0 Training loss: 2.0660 Explore P: 0.3821\n",
      "Episode: 350 Total reward: 72.0 Training loss: 21.6166 Explore P: 0.3794\n",
      "Episode: 351 Total reward: 77.0 Training loss: 1.3412 Explore P: 0.3766\n",
      "Episode: 352 Total reward: 93.0 Training loss: 32.1072 Explore P: 0.3732\n",
      "Episode: 353 Total reward: 57.0 Training loss: 1.7878 Explore P: 0.3712\n",
      "Episode: 354 Total reward: 89.0 Training loss: 2.0117 Explore P: 0.3680\n",
      "Episode: 355 Total reward: 55.0 Training loss: 2.5978 Explore P: 0.3660\n",
      "Episode: 356 Total reward: 106.0 Training loss: 64.9084 Explore P: 0.3622\n",
      "Episode: 357 Total reward: 55.0 Training loss: 37.5592 Explore P: 0.3603\n",
      "Episode: 358 Total reward: 126.0 Training loss: 30.0829 Explore P: 0.3559\n",
      "Episode: 359 Total reward: 56.0 Training loss: 1.5329 Explore P: 0.3540\n",
      "Episode: 360 Total reward: 48.0 Training loss: 2.1145 Explore P: 0.3523\n",
      "Episode: 361 Total reward: 73.0 Training loss: 1.6543 Explore P: 0.3499\n",
      "Episode: 362 Total reward: 59.0 Training loss: 1.6030 Explore P: 0.3479\n",
      "Episode: 363 Total reward: 37.0 Training loss: 2.2881 Explore P: 0.3466\n",
      "Episode: 364 Total reward: 76.0 Training loss: 90.5811 Explore P: 0.3441\n",
      "Episode: 365 Total reward: 68.0 Training loss: 139.2772 Explore P: 0.3418\n",
      "Episode: 366 Total reward: 56.0 Training loss: 36.5250 Explore P: 0.3399\n",
      "Episode: 367 Total reward: 51.0 Training loss: 1.5505 Explore P: 0.3383\n",
      "Episode: 368 Total reward: 70.0 Training loss: 2.5415 Explore P: 0.3360\n",
      "Episode: 369 Total reward: 166.0 Training loss: 2.4281 Explore P: 0.3306\n",
      "Episode: 370 Total reward: 36.0 Training loss: 37.7028 Explore P: 0.3295\n",
      "Episode: 371 Total reward: 93.0 Training loss: 2.1307 Explore P: 0.3265\n",
      "Episode: 372 Total reward: 124.0 Training loss: 1.0070 Explore P: 0.3226\n",
      "Episode: 373 Total reward: 44.0 Training loss: 57.5386 Explore P: 0.3212\n",
      "Episode: 374 Total reward: 85.0 Training loss: 60.3844 Explore P: 0.3186\n",
      "Episode: 375 Total reward: 74.0 Training loss: 89.2767 Explore P: 0.3163\n",
      "Episode: 376 Total reward: 30.0 Training loss: 2.5407 Explore P: 0.3154\n",
      "Episode: 377 Total reward: 44.0 Training loss: 1.6578 Explore P: 0.3141\n",
      "Episode: 378 Total reward: 154.0 Training loss: 64.9045 Explore P: 0.3094\n",
      "Episode: 379 Total reward: 140.0 Training loss: 70.6547 Explore P: 0.3052\n",
      "Episode: 380 Total reward: 50.0 Training loss: 73.5056 Explore P: 0.3038\n",
      "Episode: 381 Total reward: 124.0 Training loss: 2.6973 Explore P: 0.3002\n",
      "Episode: 382 Total reward: 120.0 Training loss: 1.1762 Explore P: 0.2967\n",
      "Episode: 383 Total reward: 91.0 Training loss: 0.7365 Explore P: 0.2941\n",
      "Episode: 384 Total reward: 141.0 Training loss: 1.8276 Explore P: 0.2901\n",
      "Episode: 385 Total reward: 35.0 Training loss: 2.3326 Explore P: 0.2891\n",
      "Episode: 386 Total reward: 98.0 Training loss: 2.1190 Explore P: 0.2864\n",
      "Episode: 387 Total reward: 107.0 Training loss: 30.3360 Explore P: 0.2835\n",
      "Episode: 388 Total reward: 11.0 Training loss: 1.8449 Explore P: 0.2832\n",
      "Episode: 389 Total reward: 48.0 Training loss: 3.2080 Explore P: 0.2819\n",
      "Episode: 390 Total reward: 42.0 Training loss: 2.9647 Explore P: 0.2807\n",
      "Episode: 391 Total reward: 54.0 Training loss: 2.8238 Explore P: 0.2793\n",
      "Episode: 392 Total reward: 63.0 Training loss: 1.5445 Explore P: 0.2776\n",
      "Episode: 393 Total reward: 45.0 Training loss: 72.0698 Explore P: 0.2764\n",
      "Episode: 394 Total reward: 60.0 Training loss: 34.2019 Explore P: 0.2748\n",
      "Episode: 395 Total reward: 56.0 Training loss: 2.7679 Explore P: 0.2733\n",
      "Episode: 396 Total reward: 73.0 Training loss: 2.4018 Explore P: 0.2714\n",
      "Episode: 397 Total reward: 85.0 Training loss: 192.3701 Explore P: 0.2692\n",
      "Episode: 398 Total reward: 58.0 Training loss: 36.2645 Explore P: 0.2677\n",
      "Episode: 399 Total reward: 33.0 Training loss: 3.5514 Explore P: 0.2668\n",
      "Episode: 400 Total reward: 107.0 Training loss: 44.3225 Explore P: 0.2641\n",
      "Episode: 401 Total reward: 61.0 Training loss: 2.1248 Explore P: 0.2625\n",
      "Episode: 402 Total reward: 53.0 Training loss: 81.6787 Explore P: 0.2612\n",
      "Episode: 403 Total reward: 91.0 Training loss: 1.2457 Explore P: 0.2589\n",
      "Episode: 404 Total reward: 66.0 Training loss: 59.4034 Explore P: 0.2573\n",
      "Episode: 405 Total reward: 94.0 Training loss: 66.0979 Explore P: 0.2550\n",
      "Episode: 406 Total reward: 95.0 Training loss: 92.0415 Explore P: 0.2527\n",
      "Episode: 407 Total reward: 104.0 Training loss: 168.5531 Explore P: 0.2502\n",
      "Episode: 409 Total reward: 29.0 Training loss: 1.8680 Explore P: 0.2447\n",
      "Episode: 410 Total reward: 60.0 Training loss: 1.5454 Explore P: 0.2433\n",
      "Episode: 412 Total reward: 87.0 Training loss: 1.5470 Explore P: 0.2367\n",
      "Episode: 413 Total reward: 118.0 Training loss: 1.0821 Explore P: 0.2341\n",
      "Episode: 414 Total reward: 181.0 Training loss: 50.6582 Explore P: 0.2300\n",
      "Episode: 416 Total reward: 34.0 Training loss: 0.8767 Explore P: 0.2249\n",
      "Episode: 417 Total reward: 111.0 Training loss: 188.3489 Explore P: 0.2226\n",
      "Episode: 418 Total reward: 77.0 Training loss: 79.9735 Explore P: 0.2209\n",
      "Episode: 419 Total reward: 44.0 Training loss: 2.0807 Explore P: 0.2200\n",
      "Episode: 420 Total reward: 53.0 Training loss: 1.1612 Explore P: 0.2189\n",
      "Episode: 421 Total reward: 130.0 Training loss: 1.5576 Explore P: 0.2162\n",
      "Episode: 422 Total reward: 117.0 Training loss: 241.7786 Explore P: 0.2138\n",
      "Episode: 423 Total reward: 127.0 Training loss: 1.3992 Explore P: 0.2112\n",
      "Episode: 425 Total reward: 61.0 Training loss: 1.1963 Explore P: 0.2061\n",
      "Episode: 427 Total reward: 36.0 Training loss: 124.1181 Explore P: 0.2015\n",
      "Episode: 428 Total reward: 179.0 Training loss: 26.9809 Explore P: 0.1981\n",
      "Episode: 429 Total reward: 136.0 Training loss: 222.5102 Explore P: 0.1955\n",
      "Episode: 431 Total reward: 30.0 Training loss: 1.9323 Explore P: 0.1913\n",
      "Episode: 432 Total reward: 178.0 Training loss: 0.8897 Explore P: 0.1881\n",
      "Episode: 433 Total reward: 166.0 Training loss: 1.5918 Explore P: 0.1852\n",
      "Episode: 434 Total reward: 133.0 Training loss: 1.1645 Explore P: 0.1829\n",
      "Episode: 435 Total reward: 174.0 Training loss: 1.2502 Explore P: 0.1799\n",
      "Episode: 436 Total reward: 161.0 Training loss: 1.2290 Explore P: 0.1772\n",
      "Episode: 438 Total reward: 42.0 Training loss: 0.5479 Explore P: 0.1732\n",
      "Episode: 439 Total reward: 121.0 Training loss: 1.3965 Explore P: 0.1712\n",
      "Episode: 440 Total reward: 103.0 Training loss: 0.8403 Explore P: 0.1696\n",
      "Episode: 441 Total reward: 192.0 Training loss: 1.1303 Explore P: 0.1665\n",
      "Episode: 443 Total reward: 58.0 Training loss: 1.0371 Explore P: 0.1626\n",
      "Episode: 445 Total reward: 53.0 Training loss: 0.7135 Explore P: 0.1587\n",
      "Episode: 447 Total reward: 51.0 Training loss: 0.9635 Explore P: 0.1551\n",
      "Episode: 448 Total reward: 146.0 Training loss: 0.5701 Explore P: 0.1530\n",
      "Episode: 450 Total reward: 80.0 Training loss: 36.0150 Explore P: 0.1490\n",
      "Episode: 452 Total reward: 102.0 Training loss: 1.0131 Explore P: 0.1449\n",
      "Episode: 454 Total reward: 4.0 Training loss: 93.5358 Explore P: 0.1421\n",
      "Episode: 456 Total reward: 42.0 Training loss: 56.0510 Explore P: 0.1390\n",
      "Episode: 459 Total reward: 99.0 Training loss: 0.4302 Explore P: 0.1327\n",
      "Episode: 461 Total reward: 66.0 Training loss: 1.1224 Explore P: 0.1295\n",
      "Episode: 463 Total reward: 140.0 Training loss: 1.1690 Explore P: 0.1255\n",
      "Episode: 466 Total reward: 34.0 Training loss: 0.9126 Explore P: 0.1206\n",
      "Episode: 468 Total reward: 197.0 Training loss: 0.4237 Explore P: 0.1163\n",
      "Episode: 469 Total reward: 151.0 Training loss: 1.0661 Explore P: 0.1147\n",
      "Episode: 472 Total reward: 90.0 Training loss: 0.5131 Explore P: 0.1097\n",
      "Episode: 474 Total reward: 175.0 Training loss: 0.5164 Explore P: 0.1060\n",
      "Episode: 477 Total reward: 46.0 Training loss: 0.2449 Explore P: 0.1018\n",
      "Episode: 479 Total reward: 17.0 Training loss: 0.5640 Explore P: 0.0999\n",
      "Episode: 482 Total reward: 99.0 Training loss: 0.6039 Explore P: 0.0955\n",
      "Episode: 483 Total reward: 138.0 Training loss: 0.1930 Explore P: 0.0943\n",
      "Episode: 485 Total reward: 25.0 Training loss: 0.1360 Explore P: 0.0924\n",
      "Episode: 486 Total reward: 108.0 Training loss: 0.2623 Explore P: 0.0915\n",
      "Episode: 488 Total reward: 102.0 Training loss: 0.5491 Explore P: 0.0891\n",
      "Episode: 489 Total reward: 145.0 Training loss: 0.2327 Explore P: 0.0880\n",
      "Episode: 490 Total reward: 113.0 Training loss: 0.5579 Explore P: 0.0871\n",
      "Episode: 491 Total reward: 116.0 Training loss: 0.6404 Explore P: 0.0862\n",
      "Episode: 493 Total reward: 44.0 Training loss: 0.2607 Explore P: 0.0844\n",
      "Episode: 494 Total reward: 95.0 Training loss: 0.3490 Explore P: 0.0837\n",
      "Episode: 495 Total reward: 132.0 Training loss: 0.2480 Explore P: 0.0827\n",
      "Episode: 496 Total reward: 100.0 Training loss: 0.2223 Explore P: 0.0820\n",
      "Episode: 497 Total reward: 92.0 Training loss: 319.1640 Explore P: 0.0813\n",
      "Episode: 498 Total reward: 143.0 Training loss: 0.5328 Explore P: 0.0803\n",
      "Episode: 499 Total reward: 104.0 Training loss: 47.9229 Explore P: 0.0796\n",
      "Episode: 500 Total reward: 186.0 Training loss: 0.3214 Explore P: 0.0783\n",
      "Episode: 501 Total reward: 120.0 Training loss: 0.4864 Explore P: 0.0775\n",
      "Episode: 502 Total reward: 69.0 Training loss: 0.3245 Explore P: 0.0770\n",
      "Episode: 503 Total reward: 88.0 Training loss: 0.7638 Explore P: 0.0764\n",
      "Episode: 504 Total reward: 83.0 Training loss: 0.8053 Explore P: 0.0759\n",
      "Episode: 505 Total reward: 61.0 Training loss: 0.6206 Explore P: 0.0755\n",
      "Episode: 506 Total reward: 62.0 Training loss: 0.1478 Explore P: 0.0751\n",
      "Episode: 507 Total reward: 58.0 Training loss: 0.6571 Explore P: 0.0747\n",
      "Episode: 508 Total reward: 63.0 Training loss: 0.9709 Explore P: 0.0743\n",
      "Episode: 509 Total reward: 115.0 Training loss: 0.3442 Explore P: 0.0736\n",
      "Episode: 510 Total reward: 84.0 Training loss: 324.2889 Explore P: 0.0730\n",
      "Episode: 511 Total reward: 59.0 Training loss: 0.4096 Explore P: 0.0727\n",
      "Episode: 512 Total reward: 50.0 Training loss: 0.5918 Explore P: 0.0724\n",
      "Episode: 513 Total reward: 75.0 Training loss: 0.2935 Explore P: 0.0719\n",
      "Episode: 514 Total reward: 74.0 Training loss: 0.4794 Explore P: 0.0714\n",
      "Episode: 516 Total reward: 120.0 Training loss: 0.5063 Explore P: 0.0695\n",
      "Episode: 517 Total reward: 72.0 Training loss: 0.9880 Explore P: 0.0691\n",
      "Episode: 518 Total reward: 66.0 Training loss: 0.5692 Explore P: 0.0687\n",
      "Episode: 519 Total reward: 76.0 Training loss: 0.2322 Explore P: 0.0682\n",
      "Episode: 520 Total reward: 70.0 Training loss: 0.1239 Explore P: 0.0678\n",
      "Episode: 521 Total reward: 101.0 Training loss: 0.7096 Explore P: 0.0672\n",
      "Episode: 523 Total reward: 194.0 Training loss: 1.0104 Explore P: 0.0650\n",
      "Episode: 524 Total reward: 80.0 Training loss: 163.3191 Explore P: 0.0646\n",
      "Episode: 525 Total reward: 93.0 Training loss: 0.8683 Explore P: 0.0641\n",
      "Episode: 527 Total reward: 182.0 Training loss: 0.3631 Explore P: 0.0621\n",
      "Episode: 528 Total reward: 139.0 Training loss: 0.1202 Explore P: 0.0613\n",
      "Episode: 529 Total reward: 159.0 Training loss: 0.3237 Explore P: 0.0605\n",
      "Episode: 532 Total reward: 77.0 Training loss: 0.3710 Explore P: 0.0582\n",
      "Episode: 533 Total reward: 85.0 Training loss: 0.2253 Explore P: 0.0578\n",
      "Episode: 536 Total reward: 54.0 Training loss: 0.4134 Explore P: 0.0557\n",
      "Episode: 537 Total reward: 101.0 Training loss: 0.3248 Explore P: 0.0552\n",
      "Episode: 539 Total reward: 27.0 Training loss: 0.3264 Explore P: 0.0542\n",
      "Episode: 541 Total reward: 55.0 Training loss: 0.3427 Explore P: 0.0531\n",
      "Episode: 542 Total reward: 190.0 Training loss: 0.3758 Explore P: 0.0523\n",
      "Episode: 544 Total reward: 5.0 Training loss: 0.2010 Explore P: 0.0514\n",
      "Episode: 545 Total reward: 191.0 Training loss: 0.3239 Explore P: 0.0506\n",
      "Episode: 546 Total reward: 151.0 Training loss: 0.3002 Explore P: 0.0500\n",
      "Episode: 548 Total reward: 29.0 Training loss: 117.3745 Explore P: 0.0491\n",
      "Episode: 550 Total reward: 16.0 Training loss: 0.3219 Explore P: 0.0483\n",
      "Episode: 552 Total reward: 38.0 Training loss: 0.3374 Explore P: 0.0474\n",
      "Episode: 553 Total reward: 110.0 Training loss: 0.1331 Explore P: 0.0470\n",
      "Episode: 555 Total reward: 25.0 Training loss: 0.4902 Explore P: 0.0461\n",
      "Episode: 558 Total reward: 83.0 Training loss: 0.1286 Explore P: 0.0444\n",
      "Episode: 560 Total reward: 132.0 Training loss: 0.1843 Explore P: 0.0433\n",
      "Episode: 562 Total reward: 8.0 Training loss: 0.3129 Explore P: 0.0426\n",
      "Episode: 564 Total reward: 23.0 Training loss: 44.8514 Explore P: 0.0419\n",
      "Episode: 567 Total reward: 97.0 Training loss: 0.2853 Explore P: 0.0404\n",
      "Episode: 568 Total reward: 88.0 Training loss: 0.3550 Explore P: 0.0401\n",
      "Episode: 570 Total reward: 3.0 Training loss: 0.3561 Explore P: 0.0395\n",
      "Episode: 571 Total reward: 184.0 Training loss: 0.2283 Explore P: 0.0389\n",
      "Episode: 573 Total reward: 186.0 Training loss: 0.3692 Explore P: 0.0379\n",
      "Episode: 574 Total reward: 187.0 Training loss: 0.6579 Explore P: 0.0373\n",
      "Episode: 575 Total reward: 89.0 Training loss: 0.4606 Explore P: 0.0371\n",
      "Episode: 576 Total reward: 97.0 Training loss: 0.2114 Explore P: 0.0368\n",
      "Episode: 577 Total reward: 173.0 Training loss: 0.2900 Explore P: 0.0364\n",
      "Episode: 578 Total reward: 189.0 Training loss: 0.2374 Explore P: 0.0359\n",
      "Episode: 579 Total reward: 94.0 Training loss: 0.1070 Explore P: 0.0356\n",
      "Episode: 580 Total reward: 116.0 Training loss: 0.3848 Explore P: 0.0353\n",
      "Episode: 581 Total reward: 94.0 Training loss: 0.3111 Explore P: 0.0351\n",
      "Episode: 582 Total reward: 88.0 Training loss: 0.2629 Explore P: 0.0349\n",
      "Episode: 584 Total reward: 195.0 Training loss: 0.2897 Explore P: 0.0339\n",
      "Episode: 586 Total reward: 13.0 Training loss: 0.2750 Explore P: 0.0334\n",
      "Episode: 588 Total reward: 58.0 Training loss: 0.1995 Explore P: 0.0328\n",
      "Episode: 589 Total reward: 81.0 Training loss: 0.3984 Explore P: 0.0326\n",
      "Episode: 590 Total reward: 107.0 Training loss: 0.2576 Explore P: 0.0324\n",
      "Episode: 591 Total reward: 106.0 Training loss: 0.1112 Explore P: 0.0322\n",
      "Episode: 592 Total reward: 135.0 Training loss: 0.1937 Explore P: 0.0319\n",
      "Episode: 593 Total reward: 94.0 Training loss: 0.1894 Explore P: 0.0317\n",
      "Episode: 594 Total reward: 83.0 Training loss: 0.4842 Explore P: 0.0315\n",
      "Episode: 596 Total reward: 175.0 Training loss: 1.1595 Explore P: 0.0307\n",
      "Episode: 598 Total reward: 88.0 Training loss: 0.3047 Explore P: 0.0301\n",
      "Episode: 601 Total reward: 81.0 Training loss: 0.4281 Explore P: 0.0292\n",
      "Episode: 603 Total reward: 83.0 Training loss: 0.2893 Explore P: 0.0286\n",
      "Episode: 605 Total reward: 197.0 Training loss: 0.2377 Explore P: 0.0279\n",
      "Episode: 608 Total reward: 97.0 Training loss: 0.1457 Explore P: 0.0270\n",
      "Episode: 610 Total reward: 111.0 Training loss: 0.1185 Explore P: 0.0265\n",
      "Episode: 613 Total reward: 98.0 Training loss: 0.1188 Explore P: 0.0257\n",
      "Episode: 615 Total reward: 159.0 Training loss: 1.9189 Explore P: 0.0252\n",
      "Episode: 618 Total reward: 99.0 Training loss: 0.1084 Explore P: 0.0244\n",
      "Episode: 620 Total reward: 132.0 Training loss: 0.2202 Explore P: 0.0239\n",
      "Episode: 622 Total reward: 142.0 Training loss: 0.1566 Explore P: 0.0235\n",
      "Episode: 624 Total reward: 172.0 Training loss: 0.0920 Explore P: 0.0230\n",
      "Episode: 627 Total reward: 99.0 Training loss: 0.1848 Explore P: 0.0224\n",
      "Episode: 630 Total reward: 99.0 Training loss: 0.1192 Explore P: 0.0217\n",
      "Episode: 633 Total reward: 99.0 Training loss: 0.1581 Explore P: 0.0212\n",
      "Episode: 636 Total reward: 99.0 Training loss: 0.1002 Explore P: 0.0206\n",
      "Episode: 639 Total reward: 99.0 Training loss: 0.1296 Explore P: 0.0201\n",
      "Episode: 642 Total reward: 99.0 Training loss: 0.1879 Explore P: 0.0196\n",
      "Episode: 645 Total reward: 99.0 Training loss: 0.0771 Explore P: 0.0192\n",
      "Episode: 648 Total reward: 99.0 Training loss: 0.0446 Explore P: 0.0187\n",
      "Episode: 651 Total reward: 99.0 Training loss: 0.0900 Explore P: 0.0183\n",
      "Episode: 654 Total reward: 99.0 Training loss: 0.0455 Explore P: 0.0179\n",
      "Episode: 657 Total reward: 99.0 Training loss: 0.0866 Explore P: 0.0175\n",
      "Episode: 660 Total reward: 99.0 Training loss: 0.2129 Explore P: 0.0171\n",
      "Episode: 663 Total reward: 59.0 Training loss: 0.1953 Explore P: 0.0168\n",
      "Episode: 666 Total reward: 99.0 Training loss: 0.1724 Explore P: 0.0165\n",
      "Episode: 669 Total reward: 99.0 Training loss: 0.2233 Explore P: 0.0162\n",
      "Episode: 672 Total reward: 99.0 Training loss: 0.2891 Explore P: 0.0159\n",
      "Episode: 675 Total reward: 99.0 Training loss: 0.2632 Explore P: 0.0156\n",
      "Episode: 678 Total reward: 99.0 Training loss: 0.3889 Explore P: 0.0153\n",
      "Episode: 681 Total reward: 99.0 Training loss: 0.7374 Explore P: 0.0151\n",
      "Episode: 684 Total reward: 99.0 Training loss: 0.2640 Explore P: 0.0148\n",
      "Episode: 687 Total reward: 99.0 Training loss: 0.2292 Explore P: 0.0146\n",
      "Episode: 690 Total reward: 99.0 Training loss: 0.2066 Explore P: 0.0143\n",
      "Episode: 693 Total reward: 99.0 Training loss: 0.4697 Explore P: 0.0141\n",
      "Episode: 696 Total reward: 99.0 Training loss: 0.7455 Explore P: 0.0139\n",
      "Episode: 699 Total reward: 99.0 Training loss: 0.4564 Explore P: 0.0137\n",
      "Episode: 702 Total reward: 99.0 Training loss: 1.1287 Explore P: 0.0136\n",
      "Episode: 705 Total reward: 99.0 Training loss: 1.1411 Explore P: 0.0134\n",
      "Episode: 706 Total reward: 12.0 Training loss: 1.1141 Explore P: 0.0134\n",
      "Episode: 708 Total reward: 136.0 Training loss: 1.6583 Explore P: 0.0133\n",
      "Episode: 709 Total reward: 8.0 Training loss: 0.9540 Explore P: 0.0133\n",
      "Episode: 710 Total reward: 12.0 Training loss: 1.1729 Explore P: 0.0133\n",
      "Episode: 711 Total reward: 11.0 Training loss: 1.2110 Explore P: 0.0133\n",
      "Episode: 712 Total reward: 9.0 Training loss: 1.2839 Explore P: 0.0133\n",
      "Episode: 713 Total reward: 12.0 Training loss: 1.6129 Explore P: 0.0133\n",
      "Episode: 714 Total reward: 10.0 Training loss: 1.1057 Explore P: 0.0133\n",
      "Episode: 715 Total reward: 9.0 Training loss: 0.6985 Explore P: 0.0132\n",
      "Episode: 716 Total reward: 9.0 Training loss: 1.5027 Explore P: 0.0132\n",
      "Episode: 717 Total reward: 11.0 Training loss: 1.4280 Explore P: 0.0132\n",
      "Episode: 718 Total reward: 8.0 Training loss: 0.9326 Explore P: 0.0132\n",
      "Episode: 719 Total reward: 9.0 Training loss: 1.1078 Explore P: 0.0132\n",
      "Episode: 720 Total reward: 10.0 Training loss: 1.1457 Explore P: 0.0132\n",
      "Episode: 721 Total reward: 12.0 Training loss: 0.9900 Explore P: 0.0132\n",
      "Episode: 722 Total reward: 10.0 Training loss: 1.0103 Explore P: 0.0132\n",
      "Episode: 723 Total reward: 11.0 Training loss: 1.0580 Explore P: 0.0132\n",
      "Episode: 724 Total reward: 12.0 Training loss: 1.0083 Explore P: 0.0132\n",
      "Episode: 725 Total reward: 11.0 Training loss: 1.9773 Explore P: 0.0132\n",
      "Episode: 726 Total reward: 11.0 Training loss: 1.0157 Explore P: 0.0132\n",
      "Episode: 727 Total reward: 9.0 Training loss: 0.6659 Explore P: 0.0132\n",
      "Episode: 730 Total reward: 99.0 Training loss: 0.9715 Explore P: 0.0131\n",
      "Episode: 732 Total reward: 40.0 Training loss: 2.3196 Explore P: 0.0130\n",
      "Episode: 733 Total reward: 61.0 Training loss: 2.6767 Explore P: 0.0130\n",
      "Episode: 734 Total reward: 37.0 Training loss: 2.7649 Explore P: 0.0130\n",
      "Episode: 735 Total reward: 38.0 Training loss: 3.1089 Explore P: 0.0129\n",
      "Episode: 736 Total reward: 12.0 Training loss: 3.9944 Explore P: 0.0129\n",
      "Episode: 737 Total reward: 12.0 Training loss: 4.3864 Explore P: 0.0129\n",
      "Episode: 738 Total reward: 12.0 Training loss: 4.2763 Explore P: 0.0129\n",
      "Episode: 739 Total reward: 10.0 Training loss: 3.3291 Explore P: 0.0129\n",
      "Episode: 740 Total reward: 24.0 Training loss: 2.9997 Explore P: 0.0129\n",
      "Episode: 741 Total reward: 12.0 Training loss: 3.1369 Explore P: 0.0129\n",
      "Episode: 742 Total reward: 13.0 Training loss: 3.9775 Explore P: 0.0129\n",
      "Episode: 743 Total reward: 25.0 Training loss: 0.7715 Explore P: 0.0129\n",
      "Episode: 744 Total reward: 9.0 Training loss: 3.8481 Explore P: 0.0129\n",
      "Episode: 745 Total reward: 12.0 Training loss: 3.6113 Explore P: 0.0129\n",
      "Episode: 746 Total reward: 10.0 Training loss: 1048.1128 Explore P: 0.0129\n",
      "Episode: 747 Total reward: 11.0 Training loss: 2.5466 Explore P: 0.0129\n",
      "Episode: 748 Total reward: 10.0 Training loss: 2.2137 Explore P: 0.0129\n",
      "Episode: 749 Total reward: 19.0 Training loss: 1322.7770 Explore P: 0.0129\n",
      "Episode: 750 Total reward: 16.0 Training loss: 4.0587 Explore P: 0.0129\n",
      "Episode: 751 Total reward: 12.0 Training loss: 3.9079 Explore P: 0.0129\n",
      "Episode: 752 Total reward: 8.0 Training loss: 4.9659 Explore P: 0.0129\n",
      "Episode: 753 Total reward: 9.0 Training loss: 2.9553 Explore P: 0.0129\n",
      "Episode: 754 Total reward: 12.0 Training loss: 4.1179 Explore P: 0.0129\n",
      "Episode: 755 Total reward: 10.0 Training loss: 4.4513 Explore P: 0.0129\n",
      "Episode: 756 Total reward: 16.0 Training loss: 2.5115 Explore P: 0.0129\n",
      "Episode: 757 Total reward: 14.0 Training loss: 3.1001 Explore P: 0.0129\n",
      "Episode: 758 Total reward: 14.0 Training loss: 2.3497 Explore P: 0.0129\n",
      "Episode: 759 Total reward: 13.0 Training loss: 3.3380 Explore P: 0.0128\n",
      "Episode: 760 Total reward: 13.0 Training loss: 2.9943 Explore P: 0.0128\n",
      "Episode: 761 Total reward: 16.0 Training loss: 2.3829 Explore P: 0.0128\n",
      "Episode: 762 Total reward: 10.0 Training loss: 1388.9409 Explore P: 0.0128\n",
      "Episode: 763 Total reward: 13.0 Training loss: 743.9169 Explore P: 0.0128\n",
      "Episode: 764 Total reward: 15.0 Training loss: 3.4093 Explore P: 0.0128\n",
      "Episode: 765 Total reward: 22.0 Training loss: 3.8459 Explore P: 0.0128\n",
      "Episode: 766 Total reward: 32.0 Training loss: 904.2244 Explore P: 0.0128\n",
      "Episode: 767 Total reward: 13.0 Training loss: 1.8086 Explore P: 0.0128\n",
      "Episode: 768 Total reward: 27.0 Training loss: 1.2454 Explore P: 0.0128\n",
      "Episode: 769 Total reward: 30.0 Training loss: 1109.3977 Explore P: 0.0128\n",
      "Episode: 770 Total reward: 28.0 Training loss: 2.7558 Explore P: 0.0128\n",
      "Episode: 771 Total reward: 35.0 Training loss: 828.0225 Explore P: 0.0128\n",
      "Episode: 772 Total reward: 28.0 Training loss: 220.2453 Explore P: 0.0128\n",
      "Episode: 773 Total reward: 21.0 Training loss: 1358.5247 Explore P: 0.0128\n",
      "Episode: 774 Total reward: 14.0 Training loss: 4.3852 Explore P: 0.0128\n",
      "Episode: 775 Total reward: 23.0 Training loss: 249.8062 Explore P: 0.0128\n",
      "Episode: 776 Total reward: 31.0 Training loss: 2.9748 Explore P: 0.0127\n",
      "Episode: 777 Total reward: 22.0 Training loss: 1.9131 Explore P: 0.0127\n",
      "Episode: 778 Total reward: 28.0 Training loss: 5.5997 Explore P: 0.0127\n",
      "Episode: 779 Total reward: 23.0 Training loss: 1.6080 Explore P: 0.0127\n",
      "Episode: 780 Total reward: 40.0 Training loss: 7.0404 Explore P: 0.0127\n",
      "Episode: 781 Total reward: 82.0 Training loss: 112.6858 Explore P: 0.0127\n",
      "Episode: 782 Total reward: 66.0 Training loss: 9.0796 Explore P: 0.0127\n",
      "Episode: 783 Total reward: 35.0 Training loss: 2.8746 Explore P: 0.0127\n",
      "Episode: 784 Total reward: 77.0 Training loss: 3.7438 Explore P: 0.0126\n",
      "Episode: 785 Total reward: 106.0 Training loss: 3.5551 Explore P: 0.0126\n",
      "Episode: 788 Total reward: 99.0 Training loss: 3.1472 Explore P: 0.0125\n",
      "Episode: 791 Total reward: 99.0 Training loss: 3.2609 Explore P: 0.0124\n",
      "Episode: 794 Total reward: 99.0 Training loss: 2.8919 Explore P: 0.0123\n",
      "Episode: 797 Total reward: 99.0 Training loss: 3.0274 Explore P: 0.0121\n",
      "Episode: 800 Total reward: 99.0 Training loss: 4.0758 Explore P: 0.0120\n",
      "Episode: 803 Total reward: 99.0 Training loss: 4.0875 Explore P: 0.0119\n",
      "Episode: 806 Total reward: 99.0 Training loss: 6.0483 Explore P: 0.0118\n",
      "Episode: 809 Total reward: 99.0 Training loss: 23.1490 Explore P: 0.0118\n",
      "Episode: 812 Total reward: 99.0 Training loss: 4.3253 Explore P: 0.0117\n",
      "Episode: 815 Total reward: 99.0 Training loss: 6.9659 Explore P: 0.0116\n",
      "Episode: 818 Total reward: 99.0 Training loss: 8.9741 Explore P: 0.0115\n",
      "Episode: 821 Total reward: 99.0 Training loss: 3.5489 Explore P: 0.0114\n",
      "Episode: 824 Total reward: 99.0 Training loss: 4.0151 Explore P: 0.0114\n",
      "Episode: 827 Total reward: 99.0 Training loss: 2.4719 Explore P: 0.0113\n",
      "Episode: 830 Total reward: 99.0 Training loss: 8.1381 Explore P: 0.0112\n",
      "Episode: 833 Total reward: 99.0 Training loss: 2.5030 Explore P: 0.0112\n",
      "Episode: 836 Total reward: 99.0 Training loss: 0.3857 Explore P: 0.0111\n",
      "Episode: 839 Total reward: 99.0 Training loss: 54.4214 Explore P: 0.0111\n",
      "Episode: 842 Total reward: 99.0 Training loss: 0.2432 Explore P: 0.0110\n",
      "Episode: 845 Total reward: 99.0 Training loss: 0.5110 Explore P: 0.0110\n",
      "Episode: 848 Total reward: 99.0 Training loss: 0.9588 Explore P: 0.0109\n",
      "Episode: 851 Total reward: 99.0 Training loss: 0.6830 Explore P: 0.0109\n",
      "Episode: 854 Total reward: 99.0 Training loss: 0.2768 Explore P: 0.0108\n",
      "Episode: 857 Total reward: 99.0 Training loss: 0.8840 Explore P: 0.0108\n",
      "Episode: 860 Total reward: 99.0 Training loss: 0.4210 Explore P: 0.0108\n",
      "Episode: 863 Total reward: 99.0 Training loss: 0.1121 Explore P: 0.0107\n",
      "Episode: 866 Total reward: 99.0 Training loss: 0.7516 Explore P: 0.0107\n",
      "Episode: 869 Total reward: 99.0 Training loss: 0.3561 Explore P: 0.0106\n",
      "Episode: 872 Total reward: 99.0 Training loss: 0.2227 Explore P: 0.0106\n",
      "Episode: 875 Total reward: 99.0 Training loss: 0.1176 Explore P: 0.0106\n",
      "Episode: 878 Total reward: 99.0 Training loss: 0.1348 Explore P: 0.0106\n",
      "Episode: 881 Total reward: 99.0 Training loss: 0.0677 Explore P: 0.0105\n",
      "Episode: 884 Total reward: 99.0 Training loss: 0.2189 Explore P: 0.0105\n",
      "Episode: 887 Total reward: 99.0 Training loss: 0.2065 Explore P: 0.0105\n",
      "Episode: 890 Total reward: 99.0 Training loss: 0.3010 Explore P: 0.0105\n",
      "Episode: 893 Total reward: 99.0 Training loss: 0.2953 Explore P: 0.0104\n",
      "Episode: 896 Total reward: 99.0 Training loss: 0.0803 Explore P: 0.0104\n",
      "Episode: 899 Total reward: 99.0 Training loss: 0.2251 Explore P: 0.0104\n",
      "Episode: 902 Total reward: 99.0 Training loss: 0.1251 Explore P: 0.0104\n",
      "Episode: 905 Total reward: 99.0 Training loss: 0.2102 Explore P: 0.0104\n",
      "Episode: 908 Total reward: 99.0 Training loss: 0.1638 Explore P: 0.0103\n",
      "Episode: 911 Total reward: 99.0 Training loss: 0.1701 Explore P: 0.0103\n",
      "Episode: 914 Total reward: 99.0 Training loss: 0.1785 Explore P: 0.0103\n",
      "Episode: 917 Total reward: 99.0 Training loss: 0.1984 Explore P: 0.0103\n",
      "Episode: 920 Total reward: 99.0 Training loss: 0.1727 Explore P: 0.0103\n",
      "Episode: 923 Total reward: 99.0 Training loss: 0.4291 Explore P: 0.0103\n",
      "Episode: 926 Total reward: 99.0 Training loss: 0.2107 Explore P: 0.0103\n",
      "Episode: 929 Total reward: 99.0 Training loss: 0.5943 Explore P: 0.0102\n",
      "Episode: 932 Total reward: 99.0 Training loss: 0.1558 Explore P: 0.0102\n",
      "Episode: 935 Total reward: 99.0 Training loss: 0.1966 Explore P: 0.0102\n",
      "Episode: 938 Total reward: 99.0 Training loss: 0.1255 Explore P: 0.0102\n",
      "Episode: 941 Total reward: 99.0 Training loss: 0.2359 Explore P: 0.0102\n",
      "Episode: 944 Total reward: 99.0 Training loss: 0.3458 Explore P: 0.0102\n",
      "Episode: 947 Total reward: 99.0 Training loss: 0.1993 Explore P: 0.0102\n",
      "Episode: 950 Total reward: 99.0 Training loss: 0.4365 Explore P: 0.0102\n",
      "Episode: 953 Total reward: 99.0 Training loss: 0.4178 Explore P: 0.0102\n",
      "Episode: 956 Total reward: 99.0 Training loss: 0.4965 Explore P: 0.0102\n",
      "Episode: 959 Total reward: 99.0 Training loss: 0.2516 Explore P: 0.0101\n",
      "Episode: 962 Total reward: 99.0 Training loss: 0.5793 Explore P: 0.0101\n",
      "Episode: 965 Total reward: 99.0 Training loss: 0.1812 Explore P: 0.0101\n",
      "Episode: 968 Total reward: 99.0 Training loss: 0.2547 Explore P: 0.0101\n",
      "Episode: 971 Total reward: 99.0 Training loss: 0.2306 Explore P: 0.0101\n",
      "Episode: 974 Total reward: 99.0 Training loss: 0.2395 Explore P: 0.0101\n",
      "Episode: 977 Total reward: 99.0 Training loss: 0.5166 Explore P: 0.0101\n",
      "Episode: 980 Total reward: 95.0 Training loss: 0.3957 Explore P: 0.0101\n",
      "Episode: 983 Total reward: 99.0 Training loss: 0.4137 Explore P: 0.0101\n",
      "Episode: 986 Total reward: 39.0 Training loss: 0.2750 Explore P: 0.0101\n",
      "Episode: 988 Total reward: 193.0 Training loss: 0.1944 Explore P: 0.0101\n",
      "Episode: 990 Total reward: 171.0 Training loss: 0.4022 Explore P: 0.0101\n",
      "Episode: 992 Total reward: 154.0 Training loss: 241.2445 Explore P: 0.0101\n",
      "Episode: 994 Total reward: 133.0 Training loss: 0.3103 Explore P: 0.0101\n",
      "Episode: 995 Total reward: 42.0 Training loss: 0.3313 Explore P: 0.0101\n",
      "Episode: 997 Total reward: 136.0 Training loss: 0.2825 Explore P: 0.0101\n",
      "Episode: 999 Total reward: 179.0 Training loss: 0.1865 Explore P: 0.0101\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # Uncomment this next line to watch the training\n",
    "#             env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train network\n",
    "            target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0)\n",
    "            \n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "        \n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below we plot the total rewards for each episode. The rolling average is plotted in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total Reward')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07994391d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Atari Games\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](fig/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
