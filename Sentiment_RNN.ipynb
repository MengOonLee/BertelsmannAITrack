{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/BertelsmannAITrack/blob/Lesson09/Sentiment_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5af3bbkBSNBR",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis with an RNN\n",
        "\n",
        "In this notebook, you'll implement a recurrent neural network that performs sentiment analysis.\n",
        "\n",
        "- Using an RNN rather than a strictly feedforward network is more accurate since we can include information about the sequence of words.\n",
        "\n",
        "Here we'll use a dataset of movie reviews, accompanied by sentiment labels: positive or negative.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/sentiment-rnn/assets/reviews_ex.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFYxU1-oPTAQ",
        "colab_type": "text"
      },
      "source": [
        "## Network Architecture\n",
        "\n",
        "The architecture for this network is shown below.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/sentiment-rnn/assets/network_diagram.png)\n",
        "\n",
        "\n",
        "\n",
        "- First, we'll pass in words to an embedding layer. We need an embedding layer because we have tens of thousands of words, so we'll need a more efficient representation for our input data than one-hot encoded vectors. You should have seen this before from the Word2Vec lesson. You can actually train an embedding with the Skip-gram Word2Vec model and use those embeddings as input, here. However, it's good enough to just have an embedding layer and let the network learn a different embedding table on its own. In this case, the embedding layer is for dimensionality reduction, rather than for learning semantic representations.\n",
        "\n",
        "- After input words are passed to an embedding layer, the new embeddings will be passed to LSTM cells. The LSTM cells will add recurrent connections to the network and give us the ability to include information about the sequence of words in the movie review data.\n",
        "\n",
        "- Finally, the LSTM outputs will go to a sigmoid output layer. We're using a sigmoid function because positive and negative = 1 and 0, respectively, and a sigmoid will output predicted, sentiment values between 0-1.\n",
        "\n",
        "We don't care about the sigmoid outputs except for the very last one; we can ignore the rest. We'll calculate the loss by comparing the output at the last time step and the training label (pos or neg)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYa_gPGH7eMD",
        "colab_type": "text"
      },
      "source": [
        "## Load in and visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qU4b_j47w0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "\n",
        "rm -rf data\n",
        "mkdir -p data\n",
        "wget -q https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/sentiment-rnn/data/reviews.txt -O ./data/reviews.txt\n",
        "wget -q https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/sentiment-rnn/data/labels.txt -O ./data/labels.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M6KquxD3bMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# read data from text files\n",
        "with open('data/reviews.txt', 'r') as f:\n",
        "    reviews = f.read()\n",
        "with open('data/labels.txt', 'r') as f:\n",
        "    labels = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZibG3qm778GF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "40364c02-2541-410b-d8e2-04a882cfb16c"
      },
      "source": [
        "print(reviews[:2000])\n",
        "print()\n",
        "print(labels[:20])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
            "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  \n",
            "homelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter . most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets .  br    br   but what if y\n",
            "\n",
            "positive\n",
            "negative\n",
            "po\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-l_8W7n90Ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}